{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/home/fmr/Downloads/scalpel/rescale/images'\n",
    "label_dir = '/home/fmr/Downloads/scalpel/rescale/jsons'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "\n",
    "from dataset import CustomDataset\n",
    "from dataset_aug import CustomDatasetAugmented\n",
    "from dataset_aug_albu import CustomDatasetAlbu\n",
    "from loss import compute_loss, compute_loss_smooth_focal\n",
    "from network import SimpleObjectDetector, SimpleObjectDetectorDropout,SimpleObjectDetectorRed, SimpleObjectDetectorBN, \\\n",
    "SimpleObjectDetectorWithResnet, FPN,SimpleObjectDetectorRedInput\n",
    "\n",
    "from network_attention import AttentionObjectDetector\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (512, 512 )\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 16\n",
    "\n",
    "NUM_EPOCHS = 4000\n",
    "SAVE_EVERY = 40\n",
    "MAX_OBJECTS =5\n",
    "num_classes = 5\n",
    "\n",
    "# Model\n",
    "#model = SimpleObjectDetector(input_width=224, input_height=224, num_classes=5, max_objects=5)\n",
    "#model = SimpleObjectDetector()\n",
    "#model = SimpleObjectDetectorWithResnet()\n",
    "#model = FPN()\n",
    "#model = SimpleObjectDetectorRed()\n",
    "model = SimpleObjectDetectorRedInput(input_size=INPUT_SIZE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 512, 512]             448\n",
      "              ReLU-2         [-1, 16, 512, 512]               0\n",
      "         MaxPool2d-3         [-1, 16, 256, 256]               0\n",
      "            Conv2d-4         [-1, 32, 256, 256]           4,640\n",
      "              ReLU-5         [-1, 32, 256, 256]               0\n",
      "         MaxPool2d-6         [-1, 32, 128, 128]               0\n",
      "            Conv2d-7         [-1, 64, 128, 128]          18,496\n",
      "              ReLU-8         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-9           [-1, 64, 64, 64]               0\n",
      "           Conv2d-10          [-1, 128, 64, 64]          73,856\n",
      "             ReLU-11          [-1, 128, 64, 64]               0\n",
      "        MaxPool2d-12          [-1, 128, 32, 32]               0\n",
      "           Linear-13                  [-1, 512]      67,109,376\n",
      "             ReLU-14                  [-1, 512]               0\n",
      "           Linear-15                  [-1, 256]         131,328\n",
      "             ReLU-16                  [-1, 256]               0\n",
      "           Linear-17                   [-1, 20]           5,140\n",
      "           Linear-18                   [-1, 25]           6,425\n",
      "================================================================\n",
      "Total params: 67,349,709\n",
      "Trainable params: 67,349,709\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 135.01\n",
      "Params size (MB): 256.92\n",
      "Estimated Total Size (MB): 394.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Assuming the model is defined and is named 'model'\n",
    "input_size = (3, 512, 512)  # for example, adjust if needed\n",
    "summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 5.4598e-02, -1.2611e-02,  1.5817e-03,  ...,  4.7906e-02,\n",
      "          1.7106e-02,  2.0466e-02],\n",
      "        [ 1.1705e-02,  2.3764e-02,  6.2032e-02,  ..., -6.7343e-03,\n",
      "         -3.4995e-02, -4.9746e-02],\n",
      "        [ 1.9897e-02,  1.6289e-02,  4.1104e-02,  ..., -5.4413e-02,\n",
      "         -1.1121e-02,  4.1767e-02],\n",
      "        ...,\n",
      "        [-2.1100e-05,  5.0931e-02,  1.7985e-02,  ..., -2.4838e-02,\n",
      "          5.2244e-03,  6.2292e-02],\n",
      "        [ 3.8484e-02,  9.2326e-03, -5.8533e-02,  ...,  4.9661e-02,\n",
      "          5.3062e-03,  5.2821e-02],\n",
      "        [-5.2050e-04, -3.6725e-02,  2.8297e-02,  ..., -1.7685e-02,\n",
      "          5.9900e-02,  4.4516e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0228, -0.0437, -0.0317, -0.0610,  0.0109, -0.0203,  0.0171, -0.0152,\n",
      "         0.0326, -0.0188,  0.0552, -0.0379, -0.0010,  0.0485, -0.0387,  0.0120,\n",
      "         0.0579, -0.0581,  0.0183, -0.0371,  0.0402,  0.0130,  0.0314, -0.0469,\n",
      "        -0.0056], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.fc_class.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model weights from /home/fmr/workspace/scalpel/savedweights/focallosssimplered/model_weights_epoch_4000.pt\n"
     ]
    }
   ],
   "source": [
    "weights_path = '/home/fmr/workspace/scalpel/savedweights/focallosssimplered/model_weights_epoch_4000.pt'\n",
    "\n",
    "# Initialize model here...\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "    print(f\"Loaded model weights from {weights_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocvbuild_pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
